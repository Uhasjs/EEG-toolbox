**## EEG数据预处理工具链功能文档**
**版本: 2.0**
**日期: 2025年8月31日**

### 1. 概述
本工具链将原始的、多通道的EEG数据（CSV格式）通过一系列标准化的预处理步骤，转换为干净、可用、适合进行后续特征提取和建模分析的数据。整个流程遵循“原地处理”原则，即每一步处理完成后都会覆盖更新原始文件，以保证流程的简洁性，如有需要，建议每步处理结束后备份数据文件。
处理流程遵循以下顺序：数据清理 -> 信号滤波 -> 伪迹修复
终端运行以下指令安装依赖库：pip install -r requirements.txt

### ----------------------------------------------------------------------------------------
### 模块1：数据清理与格式化
功能目标: 加载原始数据，进行初步的结构性清洗，统一数据格式，为后续的信号处理步骤做好准备。
处理流程: 终端运行data_clean def.py
1.  加载数据: 直接读取指定的 `Qinghui_Athena.csv` 文件（单样本示例数据，数据需和处理脚本在同一路径下）。
2.  筛选列: 仅保留必要的列：原始时间戳列 (`timestamps`) 和四个EEG数据列 (`eeg_1`, `eeg_2`, `eeg_3`, `eeg_4`)。所有其他无关数据列（如加速度计、陀螺仪等）被去除。
3.  重命名: 将保留的列重命名为标准格式：`time`, `CH1`, `CH2`, `CH3`, `CH4`，以提高可读性和后续处理的便利性。
4.  移除无效行: 删除在所有四个EEG通道 (`CH1` - `CH4`) 中数据均为空白的行。
5.  时间戳归零: 将绝对时间戳转换为以0为起点的相对时间（单位：s），同时保持原始数据的时间间隔和采样率不变。
6.  采样率计算: 基于处理后的时间戳，计算并显示数据的平均采样率（Hz），以供验证。
输出结果: 处理后的csv文件加后缀cleaned。更新后的文件包含5列 (`time`, `CH1`, `CH2`, `CH3`, `CH4`)，数据行数可能减少，时间戳从0开始。

### 模块2：基线校正
功能目标: 移除原始信号中较大的直流（DC）偏移量，使整个EEG波形围绕0基准线上下波动。这对于准确计算和观察后续的电位变化（如ERP成分）至关重要。
处理流程: 终端运行data_baseline_def.py
1. 加载数据: 读取由模块二清理后的 ..._cleaned.csv 文件。
2. 方法选择: 脚本内提供了两种校正方法，用户可通过注释切换：
	方法1 (固定值DC校正): 从每个数据点直接减去一个固定的偏移值（如硬件本身固有的800mV偏置）。适用于偏移量非常固定的情况。
	方法2 (基于基线期校正): (默认启用) 这是更常用和科学的方法。脚本会计算每个通道在指定“基线期”（如信号最开始的200毫秒）内的平均值，然后从该通道的所有数据点中减去这个各自的平均值。
3. 参数配置: 用户可以在主函数中自定义BASELINE_WINDOW参数，以精确设定用于计算平均值的基线时间窗口。
输出结果: 生成一个新的csv文件，命名为 ..._baseline.csv。文件中的EEG数据不再有较大的正向偏移，而是围绕0上下波动，可以清晰地看到正负电位变化。

### 模块3：信号滤波
功能目标: 去除EEG信号中与神经活动无关的噪声成分，主要包括低频漂移、高频噪声和工频干扰。
处理流程:终端运行data_filter def.py
1.  加载数据: 读取由模块2校正后的csv文件。
2.  带通滤波 (Band-pass Filtering): 对每个EEG通道 (`CH1` - `CH4`) 应用一个0.1 Hz 至 60 Hz的带通滤波器。
0.1 Hz低频截止: 能够有效移除非常缓慢的信号漂移和核心的直流偏移（DC Offset）。
60 Hz高频截止: 能够有效移除大部分高频肌肉噪声（EMG）和其他环境噪声。
3.  陷波滤波 (Notch Filtering): 紧接着，对已进行带通滤波的信号再应用一个49 Hz 至 51 Hz的陷波滤波器。此步骤能够精确地去除由电力线路引入的50 Hz工频干扰及其附近的噪声。
输出结果：处理后的csv文件加后缀filtered。文件中的EEG通道数据变为滤波后的值，其直流偏移已被移除（数据围绕0波动，出现负值），并且不含50Hz工频干扰。

### 模块4：伪迹修复（极值插值）
功能目标: 处理在滤波后仍然存在的、短暂的、非生理性的极端幅值点（如电极瞬时接触不良、静电等造成的尖峰脉冲），同时不破坏数据的时间连续性。
处理流程:终端运行0data_AmpRemove def.py
1.  加载数据: 读取由模块3滤波后的 csv文件。
2.  极值检测: 设定一个合理的生理信号振幅阈值（±100 微伏）。遍历每个EEG通道，查找所有绝对值超过该阈值的数据点。
3.  标记与插值:
a. 将所有检测到的“极值点”临时标记为无效值。
b. 使用线性插值法，根据每个无效点前后的有效数据点，计算出新的、合理的值来替换该无效点。
输出结果：处理后的csv文件加后缀remove。文件中一些短暂的、幅值异常的点被平滑修复，数据整体看起来更平稳。

### 模块5：数据缩放 (标准化)
功能目标: 将修复后的EEG数据进行标准化处理，使其均值为0，标准差为1。此步骤对于许多机器学习算法的性能至关重要，它可以消除不同通道间的量纲差异，并改善模型的收敛速度和稳定性。
处理流程: 终端运行data_scaler_def.py
1. 加载数据: 读取由模块4修复后的数据文件。
2. 标准化 (Standardization): 对每个EEG通道 (CH1 - CH4) 的时间序列数据独立进行Z-score标准化。计算每个通道自身的均值和标准差，然后对该通道的每个数据点执行 (值 - 均值) / 标准差 的运算。
3. 数据更新: 脚本提供了标准化和归一化（缩放到[0,1]范围）两种方法，默认使用标准化。用户可根据需要在代码中轻松切换。
4. 输出结果: 处理后的csv文件加后缀nml(归一化)或std(标准化)。文件中EEG通道数据的数值范围被调整，每个通道的数据分布均值为0，标准差为1，但信号的波形形态和动态变化被完整保留。

### 模块6：数据特征提取
6.1 子模块：数据分段 (Epoching)
此部分标志着预处理的结束和分析的开始。后续模块将从处理好的时序信号中提取有意义的生物学特征，并生成新的特征文件。
功能目标: 将连续的EEG时间序列数据，切割成等长的、离散的片段 (Epochs)。这是进行事件相关分析和计算基于Epoch的特征的必要前提。
处理流程: 终端运行data_epoch.py
1. 加载数据: 读取由前序模块处理后的连续数据文件。
2. 参数设定: 用户可以在脚本中设定window_sec参数，以定义每个Epoch的时长，默认为1秒。
3. 数据切割: 脚本会自动计算并切割出整数个完整的Epochs，舍弃末尾不足一个Epoch的数据。
4. 添加ID: 为切割后的数据新增一列 epoch_id，用于唯一标识每一个Epoch。脚本运行后会报告生成的Epoch总数。
输出结果: 生成一个新的CSV文件，命名为 ..._epoched.csv。该文件在原有数据基础上新增了epoch_id列，为后续的按段分析做好了准备。

6.2 子模块：功率谱密度 (PSD) 特征
功能目标: 分析EEG信号在频域上的能量分布，并提取各个经典脑电频带（如Delta, Alpha, Beta等）的相对功率作为核心特征。
处理流程: 终端运行data_psd_def.py
1. 加载数据: 读取由模块四标准化后的数据文件。
2. 配置频带: 用户可以在脚本顶部的“配置区”轻松修改一个列表 (BANDS_TO_EXTRACT)，来选择希望提取的一个或多个频带特征。脚本内置了Delta, Theta, Alpha, Alpha1, Alpha2, Beta1, Beta2, Gamma1等所有标准频带作为“菜单”供选择。
3. 计算平均PSD:
	a. 脚本采用韦尔奇法 (Welch's method) 计算每个通道的功率谱密度。
	b. 计算所有四个通道的平均功率谱，得到一个代表全脑平均状态的频谱。
4. 提取频带特征:
	a. 根据用户选择的频带列表，脚本会计算每个频带内的总功率（通过对PSD曲线求和）。
	b. 计算每个频带的相对功率（即该频带功率占总功率的百分比），这是一个稳定且常用的生物标志物。
输出结果: 生成一个新的CSV文件，命名为 ..._psd.csv。文件包含：
	frequency: 完整的频率轴。
	power: 对应每个频率点的平均功率谱密度值。
	[频带名]_rel_power: 每一个被选定的频带的相对功率值（例如 Alpha_rel_power），作为一个新的特征列。

6.3 子模块：动态功能连接 (wPLI) 特征 (通道间同步)
功能目标: 参考时频分析结构，采用滑动窗法，计算并追踪不同脑区信号相位同步性的动态变化。这可以揭示大脑网络的“信息交流”模式是如何随时间演变的。
wPLI是一种稳健的相位同步指标，它通过计算“有符号虚部的平均值”和“虚部绝对值的平均值”的比值，能有效抵抗因容积传导产生的伪影，对0度和180度的伪影不敏感。此方法适用于事件相关的分析。
处理流程: 终端运行data_dyn_wpli.py (基于连续数据)
1. 加载数据: 读取由模块四标准化后的连续数据文件。
2. 配置参数: 用户可以在脚本顶部的“配置区”自定义三个核心参数：
	BAND: 选择要分析的频带，如 (8, 12) 代表Alpha波。
	WIN_SEC: 滑动窗的窗长（单位：秒），决定了每次计算所用的数据量。
	STEP_SEC: 滑动窗的步长（单位：秒），决定了时间分辨率。
3. 滑动窗分析:
	a. 脚本在整个时间序列上滑动一个窗口。
	b. 在每个窗口内，对所有EEG通道数据进行带通滤波，并计算所有6个通道配对（如CH1-CH2, CH1-CH3等）的加权相位滞后指数 (wPLI)。wPLI是一种能有效抑制伪影的稳健的连接性指标。
	c. 同时计算6个连接值的平均值avg_wpli。
输出结果: 生成一个新的CSV文件，命名为 ..._dyn_wpli_[频带].csv。该文件包含多行数据，每一行都代表一个时间窗的分析结果：
	time: 每个时间窗的中心时间点。
	avg_wpli: 该时间窗内，4个通道的平均连接强度。
	CH1-CH2, CH1-CH3, ...: 该时间窗内，所有6个独立配对的连接强度值。
这个文件完整地描绘了一条“功能连接强度随时间变化”的曲线。

6.4 子模块：基于Epoch的功能连接 (wPLI)
功能目标: 基于预先分段好的Epochs，计算每个Epoch内部通道之间的功能连接强度，和6.3分段逻辑不同，计算方法一样。
处理流程: 终端运行data_wpli_epoched.py
1. 加载数据: 此脚本必须使用由模块五生成的 ..._epoched.csv 分段数据文件。
2. 配置参数: 用户可以在脚本顶部的“配置区”自定义要分析的BAND（频带范围）。
3. 按Epoch分组计算: 脚本会自动根据epoch_id列对数据进行分组，并对每个Epoch的数据独立执行以下操作：
	a. 对该Epoch内的所有通道数据进行带通滤波。
	b. 计算所有6个通道配对的wPLI值。
	c. 计算该Epoch的平均wPLI值。
输出结果: 生成一个新的CSV文件，命名为 ..._wpli_[频带].csv。该文件包含多行数据，每一行代表一个独立的Epoch及其对应的功能连接特征值：
	epoch_id: 对应每个Epoch的ID。
	avg_wpli: 该Epoch的平均连接强度。
	CH1-CH2, CH1-CH3, ...: 该Epoch内，所有6个独立配对的连接强度值。

### ------------------------------------------------------------------------------------

